## 04. 평가함수

#### 필요성

추천시스템의 모델을 생성하고 해당 모델이 얼마나 잘 추천하고 있는지에 대해서 평가를 도와주는 함수

도메인이나 목적에 따라서 다른 평가 함수를 도입해서 **얼마나 잘 추천**이 되는지 평가하는게 중요

(추천에 대한 반응도 확인해야함)



### Accuracy

(예) 추천해준 영화만을 기준으로 얼만큼 고객이 봤는지(맞았는지) 정확도 계산





### F1-Score

- F1은 Precision과 Recall의 역수를 더한 값을 분모로 2를 분자로 가지는 평가함수
  - Precision은 실제 본 영화의 수 대비 추천했는데 본 영화의 수
  - Recall은 실제 추천한 영화의 수 대비 추천했는데 본 영화의 수
- 위 2가지 함수를 함께 봄으로써 추천을 통해 맞춘 영화의 비율과 추천을 안해서 안 볼 영화를 맞춘 비율을 적절하게 조절하는 평가 함수입니다.

### RMSE

추천한 평점이 얼마나 다를지? (영화 추천의 경우 사용자가 5를 평가하는 경우를 얼마나 잘 맞출지)



### MAP

> 추천의 순서를 반영한 평가 지표

각각의 순서에 따라 Precision을 먼저 계산한다. 

Precision은 실제 정답에서 얼마만큼 실제 예측에서 맞았는지를 의미 함 
$$
Precision =True Positive 
/ Actual Results(True Positive + False Positive)
$$


| Recommendations | Precision @k’s  | AP@3                          |
| --------------- | --------------- | ----------------------------- |
| [0, 0, 1]       | [0, 0, 1/3]     | (1/3)*(1/3) = 0.11            |
| [0, 1, 1]       | [0, 1/2 , 2/3]  | (1/3)[1/2 + 2/3] = 0.38       |
| [1, 1, 0]       | [1/1, 2/2, 2/3] | (1/3)[1/1 + 2/2 + 2/3] = 0.89 |
| [1, 1, 1]       | [1/1, 2/2, 3/3] | (1/3)[1 + 2/2 + 3/3] = 1      |

- Recommendations : 추천을 했는데 맞은 경우 1,  틀리면 0

- AP : Precision@k’s를평균낸값(추천한 K개의 영화의 Precision을 평균)

- MAP@4 : 4명의 사용자의 AP를 평균낸 값(Precision을 평균 낸 AP를 4명의 사용자에대해 평균)



### NDCG (Normalized Discounted Cumulative Gain) 

> 추천의 순서를 반영한 평가 지표

사용자마다 추천해주는 상품의 개수가 다를 수 있는데 이를 정규화 시켜서 평가하는 것이 NDCG

현재 추천에따른 값과 이상적 추천에 대한 값을 나누어서 계산



measure of ranking quality, 검색 알고리즘에서 성과를 측정하는 평가 메트릭

추천엔진은 user와 연관있는 documents의 집합을 추천하기 때문에, 단순히 문서 검색 작업을 수행한다고 볼 수 있다. 따라서 NDCG를 사용하여 추천엔진을 평가할 수 있다.

NDCG를 이해하기 위해서는 Cumulative Gain과 Discounted Cumuative Gain을 이해해야함

#### CG (Cumulative Gain)

relevance scores(관련성 점수) : 광고가 타겟층으로부터 받을 것으로 기대하는 긍정적 및 부정적 피드백을 기반으로 계산. 순서는 반영하지 못함



#### DGC (Discounted Cumuative Gain)

추천의 위치를 고려한 척도







