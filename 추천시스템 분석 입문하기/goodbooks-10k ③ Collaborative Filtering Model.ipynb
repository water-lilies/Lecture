{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import os, sys, gc\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(path + \"books.csv\")\n",
    "book_tags = pd.read_csv(path + \"book_tags.csv\")\n",
    "train = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + \"test.csv\")\n",
    "tags = pd.read_csv(path + \"tags.csv\")\n",
    "to_read = pd.read_csv(path + \"to_read.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['book_id'] = train['book_id'].astype(str)\n",
    "test['book_id'] = test['book_id'].astype(str)\n",
    "books['book_id'] = books['book_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_rec_model = books.sort_values(by='books_count', ascending=False)['book_id'].values[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = test.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "gt = {}\n",
    "for user in tqdm(sol['user_id'].unique()): \n",
    "    gt[user] = list(sol[sol['user_id'] == user]['unique'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = pd.DataFrame()\n",
    "rec_df['user_id'] = train['user_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD를 이용한 협업필터링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Base code : https://yamalab.tistory.com/92\n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        # predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2idx = {}\n",
    "for i, l in enumerate(train['user_id'].unique()):\n",
    "    user2idx[l] = i\n",
    "    \n",
    "book2idx = {}\n",
    "for i, l in enumerate(train['book_id'].unique()):\n",
    "    book2idx[l] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2user = {i: user for user, i in user2idx.items()}\n",
    "idx2book = {i: item for item, i in book2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[['user_id', 'book_id']].reset_index(drop=True)\n",
    "useridx = data['useridx'] = train['user_id'].apply(lambda x: user2idx[x]).values\n",
    "bookidx = data['bookidx'] = train['book_id'].apply(lambda x: book2idx[x]).values\n",
    "rating = np.ones(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "purchase_sparse = scipy.sparse.csr_matrix((rating, (useridx, bookidx)), shape=(len(set(useridx)), len(set(bookidx))))\n",
    "purchase_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = purchase_sparse.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "factorizer = MatrixFactorization(R, k=20, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del R; gc.collect() \n",
    "sgd_rec_model = factorizer.get_complete_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 읽은 책의 목록을 추출 \n",
    "read_list = train.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "read_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_list = {}\n",
    "for user in tqdm(data['useridx'].unique()):\n",
    "    rec_list = []\n",
    "    \n",
    "    # 기존에 만든 Book ID를 변경 \n",
    "    rating_scores = [(idx2book[i], c) for i, c in enumerate(sgd_rec_model[user]) if i != user] # 자기 자신이 추천안되도록 \n",
    "    rating_scores = sorted(rating_scores, key = lambda x: x[1], reverse=True) # 평점이 높은 순서대로 정렬 \n",
    "    \n",
    "    seen = read_list[read_list['user_id'] == idx2user[user]]['unique'].values[0]\n",
    "    for rec in rating_scores[0:250]: \n",
    "        if rec[0] not in seen:\n",
    "            rec_list.append(rec[0])\n",
    "    \n",
    "    if len(rec_list) < 200:\n",
    "        for i in popular_rec_model[0:200]:\n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)\n",
    "\n",
    "    total_rec_list[idx2user[user]] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import math\n",
    "\n",
    "# https://github.com/kakao-arena/brunch-article-recommendation/blob/master/evaluate.py\n",
    "\n",
    "class evaluate():\n",
    "    def __init__(self, recs, gt, topn=100):\n",
    "        self.recs = recs\n",
    "        self.gt = gt \n",
    "        self.topn = topn \n",
    "        \n",
    "    def _ndcg(self):\n",
    "        Q, S = 0.0, 0.0\n",
    "        for u, seen in six.iteritems(self.gt):\n",
    "            seen = list(set(seen))\n",
    "            rec = self.recs.get(u, [])\n",
    "            if not rec or len(seen) == 0:\n",
    "                continue\n",
    "\n",
    "            dcg = 0.0\n",
    "            idcg = sum([1.0 / math.log(i + 2, 2) for i in range(min(len(seen), len(rec)))])\n",
    "            for i, r in enumerate(rec):\n",
    "                if r not in seen:\n",
    "                    continue\n",
    "                rank = i + 1\n",
    "                dcg += 1.0 / math.log(rank + 1, 2)\n",
    "            ndcg = dcg / idcg\n",
    "            S += ndcg\n",
    "            Q += 1\n",
    "        return S / Q\n",
    "\n",
    "\n",
    "    def _map(self):\n",
    "        n, ap = 0.0, 0.0\n",
    "        for u, seen in six.iteritems(self.gt):\n",
    "            seen = list(set(seen))\n",
    "            rec = self.recs.get(u, [])\n",
    "            if not rec or len(seen) == 0:\n",
    "                continue\n",
    "\n",
    "            _ap, correct = 0.0, 0.0\n",
    "            for i, r in enumerate(rec):\n",
    "                if r in seen:\n",
    "                    correct += 1\n",
    "                    _ap += (correct / (i + 1.0))\n",
    "            _ap /= min(len(seen), len(rec))\n",
    "            ap += _ap\n",
    "            n += 1.0\n",
    "        return ap / n\n",
    "\n",
    "\n",
    "    def _entropy_diversity(self):\n",
    "        sz = float(len(self.recs)) * self.topn\n",
    "        freq = {}\n",
    "        for u, rec in six.iteritems(self.recs):\n",
    "            for r in rec:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "    \n",
    "    def _evaluate(self):\n",
    "        print('MAP@%s: %s' % (self.topn, self._map()))\n",
    "        print('NDCG@%s: %s' % (self.topn, self._ndcg()))\n",
    "        print('EntDiv@%s: %s' % (self.topn, self._entropy_diversity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS 방식을 이용한 협업필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import  *\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "from implicit.bpr import BayesianPersonalizedRanking as BPR\n",
    "\n",
    "als_model = ALS(factors=20, regularization=0.01, iterations = 100)\n",
    "als_model.fit(purchase_sparse.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model.recommend(0, purchase_sparse, N=200)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_list = {}\n",
    "for user in tqdm(data['useridx'].unique()):\n",
    "    rec_list = []\n",
    "    \n",
    "    # 기존에 만든 Book ID를 변경 \n",
    "    seen = read_list[read_list['user_id'] == idx2user[user]]['unique'].values[0]\n",
    "    recs = als_model.recommend(user, purchase_sparse, N=250)\n",
    "    recs = [idx2book[x[0]] for x in recs][0:250]  \n",
    "    \n",
    "    for rec in recs: \n",
    "        if rec not in seen:\n",
    "            rec_list.append(rec)\n",
    "    \n",
    "    if len(rec_list) < 200:\n",
    "        for i in popular_rec_model[0:200]:\n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)\n",
    "\n",
    "    total_rec_list[idx2user[user]] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
